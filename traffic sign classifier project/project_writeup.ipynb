{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Up \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The brief write up is about the traffic sign classifier. Here is a link to my project \n",
    "\n",
    "    Insert project link here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Summary & Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic data summary \n",
    "\n",
    "Numpy, pandas are used to get the basic information about the length of train, validation, and test set images,  num of classes. The result is as follows: \n",
    "    \n",
    "    Number of training examples = 34799\n",
    "    Number of testing examples = 12630\n",
    "    Image data shape = (32, 32, 1)\n",
    "    Number of classes = 43\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory data visualization \n",
    "\n",
    "A sample image which is resized to 32 by 32 pixels has been displayed along with the class index and its corrosponding label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design and Test a Model Architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data \n",
    "\n",
    "1) The images were initially converted into gray scale image\n",
    "\n",
    "2) The images obtained were later on normalised by subtracting from its mean and then scaling it by its standard deviation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture \n",
    "\n",
    "| Layer         \t\t|     Description\t        \t\t\t\t\t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| Input         \t\t| 32x32x1 Gray scale image   \t\t\t\t    | \n",
    "| Convolution 5x5     \t| 1x1 stride, valid padding, outputs 28x28x6 \t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Dropout\t\t\t\t| Keep_Probabily = 0.75\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t| 2x2 stride,  outputs 14x14x6 \t\t\t\t    |\n",
    "| Convolution 5x5\t    | 1x1 stride, valid padding, outputs 10x10x16   |\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Dropout\t\t\t\t| Keep_Probabily = 0.75\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t| 2x2 stride,  outputs 5x5x16 \t\t\t\t    |\n",
    "| Fully connected\t\t| 400 x 120       \t\t\t\t\t\t\t    |\n",
    "| ReLu\t\t\t        |\t\t\t\t\t\t\t                    |\n",
    "| Dropout\t\t\t\t|\t0.75\t\t\t\t\t\t\t\t\t\t|\n",
    "| Fully connected\t\t| 120 x 84       \t\t\t\t\t\t\t    |\n",
    "| ReLu\t\t\t        |\t\t\t\t\t\t\t                    |\n",
    "| Dropout\t\t\t\t|\t0.75\t\t\t\t\t\t\t\t\t\t|\n",
    "| Fully connected\t\t| 84 x 43       \t\t\t\t\t\t\t    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the model we used adam optimiser whichby default gives better convergence results as compared to SGD, RMS prop. And batch size of 256 was used, as this was one of the ideal values for optimal memory handling and faster convergence. And learning rate is a hyper parameter. Initially values ranging from 0.0001 to 0.1 in steps of 5 were used and optimal learning rate of 0.001 was fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model results were found to be:\n",
    "    Training set accuracy:\n",
    "    Validation set accuracy:\n",
    "    test set accuracy:\n",
    "\n",
    "\n",
    "The model was trained on Lenet data with 150 epochs. Each epoch having multiple batches of training images of size 256. \n",
    "It was found that at the end of 150th epoch, validation accuracy was: .\n",
    "The first model architecture chosen was a simple Feed Forward Neural network model without any convolution layers. The spatial structure of image was not untilised as a result the accuracy was very low. Next CNN architectures were used which showed slight increase in accuracy. Keeping with this trend. The Lenet architecture was employed. \n",
    "Dropouts were added as there was a significant difference between training and validation acc. suggesting that model needed to do better generalization.\n",
    "However,the lenet architecture was initially tried on all the RGB components of the image but later on the images were converted into gray scale components which is a weighted average of the RGB components. This drastically reduced our feature space. And training it for 150 epochs on batch size, and with appropriate hyperparamter values the accuracy was further improved. As mentioned previously model was trained for different learning rate values. So finally adding a keep_probability of 0.75, learning rate of 0.001 and batch size 256 gave our final results. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on new images\n",
    "5 German traffic signs were selected whose dimensions were 32 by 32. And those outputs are displayed in the jupyter notebook titled Traffic_Sign_Classifier.ipynb. And its output labels with actuals are displayed\n",
    "\n",
    "    for image0, Actual label:Priority road, Predicted label:Priority road\n",
    "    for image1, Actual label:Road work, Predicted label:Turn right ahead\n",
    "    for image2, Actual label:No vehicles, Predicted label:No vehicles\n",
    "    for image3, Actual label:Speed limit (60km/h), Predicted label:Speed limit (60km/h)\n",
    "    for image4, Actual label:Speed limit (60km/h), Predicted label:Speed limit (60km/h)\n",
    "    \n",
    "    \n",
    "With the following top 5 softmax probabilities. \n",
    "    The top 5 probabilties for each image is as follows \n",
    "\n",
    "    [0.9999317549218939, 6.8072005494261535e-05, 1.5241806683029889e-07, 1.5951701170628468e-08, 3.63549065357576e-09]\n",
    "    [0.76878464427969195, 0.22784060577437315, 0.0029968488754918863, 0.00021609845429273618, 0.00014937050725415203]\n",
    "    [1.0, 1.092128938504801e-17, 6.3444936042259765e-21, 9.2841967134854481e-22, 2.0122639425432881e-23]\n",
    "    [0.58157978651086206, 0.41841547730722445, 4.6948692561546953e-06, 2.2868573419478275e-08, 1.6919687182550706e-08]\n",
    "    [0.99864829143004574, 0.00067579590328409463, 0.00039179555208040088, 0.00025688448973130843, 7.7114126482664898e-06]\n",
    "    \n",
    "We see that 4 out 5 images are categorized correctly so with an accuracy of 80%, though image4 is classified correctly but only with a probability of 0.58.      \n",
    "\n",
    "We see that the model performance worsens with that of the test set provided in the dataset. This suggests that the new test data set of images may be coming from a different distribution or the sample size of 5 may not really be a good indication about the entire population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model doesn't fare well with images which are high resolution and have to be resized. And those images with multiple sign boards. The images also having traffing sign boards at an inclined angle may not be classified correclty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
