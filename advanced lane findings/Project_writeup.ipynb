{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Detection \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps were performed to obtain the lane detections\n",
    "\n",
    "1) For the given set of chessboard images, the caliberation matrix and the distortion coefficients were calculated using the call_undistort. Using these images we get the object points and image points. For our case, the chessboard size is chosen to be 9X6. An example of undistorted image is saved in output_images folder as undistorted_chessboard.jpg A sample output is saved at **./CarND-Advanced-Lane-Lines/output_images/undistorted_chessboard.jpg**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE(Single Images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distortion Corrected Image \n",
    "From the above extracted caliberation matrix and distortion coefficients, a test image was corrected for distortion using the function call_undistort. A sample output is saved at **./CarND-Advanced-Lane-Lines/output_images/undistorted_testImage.jpg**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Image Extraction \n",
    "\n",
    "The binary thresholded image is obtained from the undistorted image via binary_image function saved at **./CarND-Advanced-Lane-Lines/output_images/binary_testImage.jpg**. Here we initially use the HLS color transform, LUV, and LAB color transforms. We use the saturation channel. And we binary threshold it between \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ######## Function for retreiving a binary thresholded image ##########\n",
    "    def binary_image(img, s_thresh=(170, 255), sx_thresh=(20, 100),l_thresh = (225,255),b_thresh = (155,200)):\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)   ###### Converting RGB to HLS color format\n",
    "        s_channel = hls[:,:,2]   ###### Consdiering only the Saturation channel, as opposed to Lightness\n",
    "\n",
    "    # Grayscale image\n",
    "    # Explore gradients in other colors spaces / color channels to see what might work better\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    luv = cv2.cvtColor(img,cv2.COLOR_RGB2Luv)\n",
    "    lab = cv2.cvtColor(img,cv2.COLOR_RGB2Lab) \n",
    "    \n",
    "    \n",
    "    l_channel = luv[:,:,0]\n",
    "    b_channel = lab[:,:,2]\n",
    "    \n",
    "    # Sobel x Finding gradients along X and Y directions. \n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1) # Take the derivative in y\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    abs_sobely = np.absolute(sobely) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    abs_sobelxy = np.sqrt(abs_sobelx**2 + abs_sobely**2)\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx)) # Converting into unsigned interger format\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    # Applying appropriate thresholding make all pixels between the low and high threshold values as 1 \n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1 \n",
    "    \n",
    "    \n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh[0]) & (l_channel <= l_thresh[1])] = 1\n",
    "    \n",
    "    b_binary = np.zeros_like(b_channel)\n",
    "    b_binary[(b_channel >= b_thresh[0]) & (b_channel <= b_thresh[1])] = 1\n",
    "    # Combine the two binary thresholds\n",
    "    #### Combining binary images from sobel_x filter and s_channel images \n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(b_binary == 1) | (l_binary == 1) | (s_binary == 1) | (sxbinary == 1)] =1\n",
    "    return combined_binary\n",
    "\n",
    "For the saturation channel we use low and high threshold as 170, 255 respectively between which all are converted to 1 else 0. The other one is by considering the sobel filter gradient along the x direction. And the thresholds for this is chosen to be 20, 100. For L channel from LUV transform, we use thresholds l_thresh = (225,255) and for B channel from LAB color transform we use between 155 and 200. LUV and LAB color transforms helps in detection of yellow lanes and works well under shadowy images\n",
    "\n",
    "THe result of these two binary images are combined in such a way that if either of the pixels are 1, the result is a 1 else 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective Transform\n",
    "\n",
    "From the binary thresholded image, the perspective transform is performed by function return_warped_image saved at **./CarND-Advanced-Lane-Lines/output_images/perspective_testImage.jpg**, in which src and dst points were hardcoded as follows. \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def return_warped_image(img,x_adj=0):\n",
    "    img_height = img.shape[0]\n",
    "    img_width = img.shape[1]\n",
    "    imshape = (img_height, img_width)\n",
    "    xcenter=imshape[1]/2+x_adj\n",
    "    xfd=50\n",
    "    yf=450\n",
    "    offset=100\n",
    "    ######## Calculating source and destination points to be mapped ##########\n",
    "    ###### Based on the test images an offset of 100 is provided ###########\n",
    "    src = np.float32(\n",
    "        [(offset,imshape[0]),\n",
    "         (xcenter-xfd, yf), \n",
    "         (xcenter+xfd,yf), \n",
    "         (imshape[1]-offset,imshape[0])])\n",
    "    \n",
    "    dst = np.float32(\n",
    "        [(offset,imshape[1]),\n",
    "         (offset,0),\n",
    "         (imshape[0]-offset, 0),\n",
    "        (imshape[0]-offset,imshape[1])])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst,src)\n",
    "    warped = cv2.warpPerspective(img, M, imshape, flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "    return warped, M , Minv\n",
    "    \n",
    "This function uses the perspective transform and warpperspective methods to obtain the perspective transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting polynomial \n",
    "Sliding window is not used to detect the lane. However the left and right lanes are indicated by red and blue colors respectively. A fitted polynomial is shown in yellow color saved at **./CarND-Advanced-Lane-Lines/output_images/fitted_polynomial_testImage.jpg.**\n",
    "The lower part of the image is considered for histogram. Every column of the lower part of the image is summed up and its frequency distribution is plotted. Based on the two highest frequencies, a 2nd order polynomial is fit at those two pixel positions(along x axis) is plotted. \n",
    "\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        #cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        #(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        #cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        #(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        #pass # Remove this when you add your function\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return out_img, left_fitx,right_fitx,ploty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radius of Curvature and offset\n",
    "\n",
    "The radius of curvature is calculated in the measure_curvature_real function. And the result is printed out in Advance_Lane_Detection.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Result visual Output\n",
    "For the video we see the distance between the left and right polynomials fit, if the distance between the fit is less than 300 or greater than 600 then we use the average of past 4 best frames. The distance between the fitted lines is a sanity check so that the distance won't go out of the standard lane.\n",
    "The final edge detection is plotted onto the original image using the plot_detected_orig_image function saved at  **./CarND-Advanced-Lane-Lines/output_images/FinalResult_withdetection.jpg**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline video. \n",
    "A complete_pipeline function is implemented to run all the above steps on the video using the moviePy.editor module from python \n",
    "\n",
    "\n",
    "\n",
    "    ######## Building pipeline ########\n",
    "    global left_fitxlist\n",
    "    global right_fitxlist\n",
    "    left_fitxlist = []\n",
    "    right_fitxlist = []\n",
    "    import pdb\n",
    "    def complete_pipeline(img):\n",
    "\n",
    "    global prev_leftx\n",
    "    global prev_rightx\n",
    "    global prev_ploty\n",
    "    \n",
    "\n",
    "    \n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    #img = cv2.imread(testImagepath[0])\n",
    "    #undist = cal_undistort(img, objpoints, imgpoints)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    binaryImage = binary_image(undist)\n",
    "    perspectiveTransformImage,M,Minv = return_warped_image(binaryImage)\n",
    "    fitPolynomial,left_fitx,right_fitx,ploty = fit_polynomial(perspectiveTransformImage)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    #left_curvature= round(measure_curvature_real(left_fitx,perspectiveTransformImage.shape[0]),2)\n",
    "    #right_curvature  = round(measure_curvature_real(right_fitx,perspectiveTransformImage.shape[0]),2)\n",
    "    \n",
    "    left_curvature= round(measure_curvature_realAlt(ploty,left_fitx),2)\n",
    "    right_curvature  = round(measure_curvature_realAlt(ploty,right_fitx),2)\n",
    "    print(left_fitx)\n",
    "    \n",
    "    curv = (left_curvature+right_curvature)/2\n",
    "    curvature = \"left Rad: {} m , Right Rad: {} m\".format(left_curvature,right_curvature)\n",
    "    print(curvature)\n",
    "    offset = measure_offset(left_fitx,right_fitx,perspectiveTransformImage.shape[0],img_size[0])\n",
    "    offset = offset - 1\n",
    "    off = \"Offset: %.2f m\" % offset\n",
    "    distance = np.abs(left_fitx-right_fitx)\n",
    "    if (min(distance)>300 and max(distance)<600):\n",
    "        result= plot_detected_orig_image(off,curvature,img,undist,perspectiveTransformImage,Minv,left_fitx,right_fitx,ploty)\n",
    "        #prev_leftx = left_fitx\n",
    "        #prev_rightx = right_fitx\n",
    "        left_fitxlist.append(left_fitx)\n",
    "        right_fitxlist.append(right_fitx)\n",
    "        try:\n",
    "            prev_leftx = (left_fitxlist[-1]+left_fitxlist[-2]+left_fitxlist[-3]+left_fitxlist[-4])/4\n",
    "            prev_rightx = (right_fitxlist[-1]+right_fitxlist[-2]+right_fitxlist[-3]+right_fitxlist[-4])/4\n",
    "            prev_ploty = ploty\n",
    "        except:\n",
    "            prev_leftx = left_fitxlist[-1]\n",
    "            prev_rightx = right_fitxlist[-1]\n",
    "            prev_ploty = ploty\n",
    "            \n",
    "        #avg_leftx = \n",
    "    else:\n",
    "        #pdb.set_trace()\n",
    "        result= plot_detected_orig_image(off,curvature,img,undist,perspectiveTransformImage,Minv,prev_leftx,prev_rightx,prev_ploty)\n",
    "\n",
    "      return result\n",
    "    \n",
    "The final project video is saved at **./CarND-Advanced-Lane-Lines/output_images/project_video_alternate.mp4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Future Work\n",
    "The project works better than the cannhy edge detection. However, it likely fails on the challenge_video.mp4. A better way to work on challenge video is to play around with the threshold values for obtaining binary images. And this video won't fair better on videos with lanes of variable width. Hard coding in that scenario wouldn't work. A better way would be to get adaptable width. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
